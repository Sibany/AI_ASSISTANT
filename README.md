
# ğŸ’¬ Ollama Voice Chat AI (Multi-language)

A Streamlit-based chatbot app that lets you **talk to your local Ollama model** (e.g., `gemma3:1b`) using **text or voice** â€” with full **multi-language support**, including **translation, speech recognition**, and **TTS (Text-to-Speech)**.

---

## ğŸš€ Features

- âœ… Local LLM chatbot using Ollama (`gemma3:1b`)
- ğŸ—£ï¸ Voice input via microphone (Google Speech-to-Text)
- ğŸ”ˆ Voice output via Google Text-to-Speech (gTTS)
- ğŸŒ Multi-language support:
  - Auto translation to/from English
  - Choose your preferred voice language (e.g., Arabic, Hebrew, French)
- ğŸ˜ƒ Emoji support in chat (ignored in voice)
- ğŸ§¼ Strips special characters from voice output for cleaner TTS

---

## ğŸ›  Requirements

- Python `3.10.0`
- [Ollama](https://ollama.com/)
- `gemma3:1b` model (or any model you prefer)

---

## ğŸ“¦ Installation

### 1. Clone the repo

```bash
git clone https://github.com/yourusername/ollama-voice-chat-ai.git
cd ollama-voice-chat-ai
```

### 2. Install Ollama & Pull a Model

Make sure [Ollama](https://ollama.com/download) is installed and running:

```bash
ollama run gemma3:1b
```

> You can swap `gemma3:1b` with any other local LLM model (e.g., `mistral`, `llama2`).

### 3. Install Python dependencies

```bash
pip install -r requirements.txt
```

If you're on **Windows** and get errors with `pyaudio`:

```bash
pip install pipwin
pipwin install pyaudio
```

---

## ğŸ§  How It Works

1. User types or speaks a message (in any language).
2. Message is translated to English (if needed).
3. Sent to your **local Ollama model**.
4. Response is translated back (if needed).
5. Shown in chat + played as voice using `gTTS`.

---

## ğŸŒ Supported Languages

You can select any of the following in the dropdown:

- English (en-US)
- Arabic (ar-SA)
- Greek (el-GR)
- French (fr-FR)
- Spanish (es-ES)
- German (de-DE)
- Italian (it-IT)
- Portuguese (pt-PT)
- Russian (ru-RU)
- Chinese (zh-CN)
- Japanese (ja-JP)
- Hebrew (he-IL)

---

## ğŸ“¸ Screenshot

![Ollama Chat Multilingual UI](docs/screenshot.png)

---

## ğŸ§ª Run the App

```bash
streamlit run app.py
```

Then open [http://localhost:8501](http://localhost:8501)

---

## ğŸ“ File Structure

```
ollama-voice-chat-ai/
â”œâ”€â”€ app.py               # Main Streamlit app
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ README.md            # This file
â””â”€â”€ docs/
    â””â”€â”€ screenshot.png   # Optional image for GitHub preview
```

---

## ğŸ¤– Example Models You Can Use

- `gemma3:1b`
- `llama2`
- `mistral`
- `phi`
- `dolphin-mixtral`

> Swap models by editing the `OLLAMA_MODEL` constant in `app.py`.

---

## ğŸ™‹ FAQ

**Q: Can I use this offline?**  
Yes â€” Ollama and `gTTS` both work locally, but `gTTS` needs internet to fetch audio.

**Q: Can I add more languages?**  
Yes â€” just update the `gtts_lang_map` dictionary in `app.py`.

**Q: Can I use my own model?**  
Yes â€” any Ollama-compatible model can be used by updating the `OLLAMA_MODEL`.

---

## ğŸ“ License

MIT License â€” feel free to modify and use.

---

## ğŸ’¡ Credits

Built with [Streamlit](https://streamlit.io), [Ollama](https://ollama.com), and â¤ï¸
